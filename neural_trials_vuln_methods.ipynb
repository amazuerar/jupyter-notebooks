{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import numpy as np\n",
    "import sys\n",
    "import talos as ta\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.activations import relu, elu, tanh, sigmoid, softmax\n",
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeV = \"deadlock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD A MODEL IF YOU HAVE ONE\n",
    "#from keras.models import load_model\n",
    "#model = load_model('/obfuscated/VULN/'+typeV+'/'+typeV+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read change files\n",
    "fin = open('obfuscated/vulnerable_methods_VNV.txt', 'r')\n",
    "unique_operations = []\n",
    "for line in fin:\n",
    "    line = line.strip()\n",
    "    operations = line.split(' ')\n",
    "    for operation in operations:\n",
    "        operation = operation.strip()\n",
    "        if operation not in unique_operations:\n",
    "            unique_operations.append(operation)\n",
    "\n",
    "fin.close()\n",
    "print(unique_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the indices\n",
    "fout = open('/obfuscated/'+typeV+'/index_'+typeV+'.csv', 'w')\n",
    "for operation in unique_operations:\n",
    "    fout.write('%d,\\\"%s\\\"\\n' % (unique_operations.index(operation),operation))\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the indices\n",
    "mapping = dict()\n",
    "fin = open('obfuscated/'+typeV+'/index_'+typeV+'.csv', 'r')\n",
    "for line in fin:\n",
    "    line = line.strip()\n",
    "    index_separator = line.index(',\"')\n",
    "    index = int(line[:index_separator])\n",
    "    operation = line[index_separator+2:len(line)-1]\n",
    "    mapping[operation] = index\n",
    "fin.close()\n",
    "mapping['<PAD>'] = (len(mapping))\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the strings to vectors of numbers\n",
    "fin = open('/obfuscated/VULN/'+typeV+'/vulnerable_methods_'+typeV+'.txt', 'r')\n",
    "fout = open('/obfuscated/VULN/'+typeV+'/vulnerable_methods_numbers_'+typeV+'.txt', 'w')\n",
    "for line in fin:\n",
    "    line = line.strip()\n",
    "    operations = line.split(' ')\n",
    "    to_print = []\n",
    "    for operation in operations:\n",
    "        operation = operation.strip()\n",
    "        to_print.append(mapping[operation])\n",
    "    fout.write('%s\\n' % to_print)\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset as a tuple of lists\n",
    "dataset = list()\n",
    "fin = open('/obfuscated/VULN/'+typeV+'/vulnerable_methods_numbers_'+typeV+'.txt', 'r')\n",
    "count = 0\n",
    "for line in fin:\n",
    "    count += 1\n",
    "    dataset.append(np.array(ast.literal_eval(line)))\n",
    "    #if(count > 19999): #TO FIX\n",
    "     #   break\n",
    "fin.close()\n",
    "print(str(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create labels set, and convert it to numbers\n",
    "fin = open('/obfuscated/VULN/'+typeV+'/matching_tags_'+typeV+'.txt', 'r')\n",
    "fout = open('/obfuscated/VULN/'+typeV+'/matching_tags_numbers_'+typeV+'.txt', 'w')\n",
    "count = 0\n",
    "unique_tags = dict()\n",
    "vulnerabilities = []\n",
    "for line in fin:\n",
    "    line = line.strip()\n",
    "    unique_tags[line] = unique_tags.get(line, 0) + 1\n",
    "    if line not in vulnerabilities:\n",
    "        vulnerabilities.append(line)\n",
    "    fout.write('%d\\n' % vulnerabilities.index(line))\n",
    "fin.close()\n",
    "fout.close()\n",
    "\n",
    "print(unique_tags)\n",
    "print(\"-----------------------\")\n",
    "print(vulnerabilities)\n",
    "print(\"-----------------------\")\n",
    "print(len(vulnerabilities),'vulnerability types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the label set as numpy array\n",
    "labels = list()\n",
    "fin = open('/obfuscated/'+typeV+'/matching_tags_numbers_'+typeV+'.txt', 'r')\n",
    "count = 0\n",
    "for line in fin:\n",
    "    line = line.strip()\n",
    "    count += 1\n",
    "    labels.append(int(line))\n",
    "    #if(count > 19999): #TO FIX\n",
    "     #   break\n",
    "labels = np.array(labels)\n",
    "fin.close()\n",
    "print(str(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the length (number of operations) of the commits\n",
    "dataset = keras.preprocessing.sequence.pad_sequences(dataset,\n",
    "                                                     value=mapping[\"<PAD>\"], #Sequences that are shorter than maxlen are padded with value at the end.\n",
    "                                                     padding='post') #If not provided, is the value of the longest sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the datasets\n",
    "training_percentage = 0.8\n",
    "validation_percentage = 0.1\n",
    "test_percentage = 0.1\n",
    "\n",
    "training_size = int(len(dataset)*training_percentage)\n",
    "validation_size = int(len(dataset)*validation_percentage)\n",
    "test_size = int(len(dataset)*test_percentage)\n",
    "\n",
    "training_data = dataset[:training_size]\n",
    "training_labels = labels[:training_size]\n",
    "\n",
    "validation_data = dataset[training_size:training_size+validation_size]\n",
    "validation_labels = labels[training_size:training_size+validation_size]\n",
    "\n",
    "test_data = dataset[training_size+validation_size:]\n",
    "test_labels = labels[training_size+validation_size:]\n",
    "\n",
    "# vocabulary size\n",
    "vocab_size = len(mapping)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build the model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 32)) #Embedding layer: takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains.\n",
    "#see how to save the generated embeddings here: https://www.tensorflow.org/alpha/tutorials/sequences/word_embeddings#retrieve_the_learned_embeddings\n",
    "model.add(keras.layers.GlobalAveragePooling1D()) #returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
    "model.add(Dense(60, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#train the model (pay attention to #epochs, it strongly influences the execution time)\n",
    "history = model.fit(training_data,\n",
    "                    training_labels,\n",
    "                    epochs=2000,\n",
    "                    batch_size=46,\n",
    "                    validation_data=(validation_data, validation_labels), #monitors the accuracy on the validation set\n",
    "                    verbose=1,\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model on test data\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "predictions = model.predict_classes(test_data)\n",
    "print(results)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open('/obfuscated/'+typeV+'/predictions.csv', 'w')\n",
    "fout.write('actual,predicted,correct\\n')\n",
    "for i in range(len(predictions)):\n",
    "    fout.write('%d,%d,%r\\n' % (test_labels[i],predictions[i][0],test_labels[i] == predictions[i][0]))\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot what happened during the training\n",
    "history_dict = history.history #model.fit() returns a History object that contains a dictionary with everything that happened during training\n",
    "history_dict.keys()\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#training and validation accuracy\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes = model.predict_classes(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yhat_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_labels, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "print(\"---------\")\n",
    "precision = precision_score(test_labels, yhat_classes, average=None)\n",
    "print(precision)\n",
    "precision = precision_score(test_labels, yhat_classes, average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "print(\"---------\")\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_labels, yhat_classes, average=None)\n",
    "print(recall)\n",
    "recall = recall_score(test_labels, yhat_classes, average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "print(\"---------\")\n",
    "# # f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_labels, yhat_classes, average=None)\n",
    "print(f1)\n",
    "f1 = f1_score(test_labels, yhat_classes, average='micro')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_labels, yhat_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_names = ['deadlock', 'infinite loop', 'null pointer dereference', 'race condition', 'double free', 'dead code', 'buffer overflow', 'use after free']\n",
    "target_names = ['VULN', 'NOVULN']\n",
    "print(classification_report(test_labels, yhat_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('obfuscated/'+typeV+'/'+typeV+'.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
